{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef62abc7",
   "metadata": {},
   "source": [
    "### ObjectSerializer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a198d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from slurmflow.serializer import ObjectSerializer\n",
    "from slurmflow.config import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ca307",
   "metadata": {},
   "source": [
    "The `ObjectSerializer` is an algorithm for storing arbitrary Python objects. The serializer leverages the `h5py` library for storing hierarchical data structures and `blosc2` to compress the bytecode of serialized objects, allowing for efficient storage of large datasets.\n",
    "\n",
    "It won't work for everything (most notably objects which are wrappers around C objects, e.g. many OpenMM objects), but I have found that it works well for custom dataclasses across various packages (e.g. MDtraj trajectories, MDAnalysis universes, numpy arrays, and torch tensors).\n",
    "\n",
    "Below I have provided an example where a custom dataclass is defined, and then saved using the serializer. The stored object is then loaded and equality of checked between the original and retrieved objects. The compression factor is also reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a055a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExampleDataClass:\n",
    "    id: int\n",
    "    name: str\n",
    "    data: list\n",
    "    is_active: bool\n",
    "    config: ConfigParser\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return (self.id == other.id and\n",
    "                self.name == other.name and\n",
    "                np.array_equal(self.data, other.data) and\n",
    "                self.is_active == other.is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa77d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equality check: True\n",
      "Serialized Size: 427960 bytes\n",
      "In-Memory Size: 3205193 bytes\n",
      "Compression Factor: 7.489\n"
     ]
    }
   ],
   "source": [
    "OS = ObjectSerializer()\n",
    "cfg = ConfigParser(\"config/example.yml\") # see config.ipynb for more (here it's just an object to be stored).\n",
    "\n",
    "# Step1 1: Create an instance of the dataclass\n",
    "example_data = ExampleDataClass(1, \"Test Object\", np.arange(400000), True, cfg)\n",
    "\n",
    "# Step 2: Serialize the Object\n",
    "OS.save(example_data, \"example/example_data.h5\", overwrite=True) # overwrite should be disabled for partial saving.\n",
    "\n",
    "# Step 3: Deserialize the Object\n",
    "deserialized_data = OS.load(\"example/example_data.h5\")\n",
    "\n",
    "# Step 4: Equality Check\n",
    "is_equal = deserialized_data == example_data\n",
    "print(f\"Equality check: {is_equal}\")\n",
    "\n",
    "# Step 5: Compute Compression Factor\n",
    "\n",
    "serialized_size = os.path.getsize(\"example/example_data.h5\")\n",
    "in_memory_size = sys.getsizeof(dill.dumps(example_data))\n",
    "compression_factor = in_memory_size / serialized_size\n",
    "\n",
    "print(f\"Serialized Size: {serialized_size} bytes\")\n",
    "print(f\"In-Memory Size: {in_memory_size} bytes\")\n",
    "print(f\"Compression Factor: {compression_factor:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70aeffe",
   "metadata": {},
   "source": [
    "The contents of an archive can be printed using the `print_summary` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f232088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      "config/config_data\n",
      "config/parent_config_data\n",
      "data\n",
      "id\n",
      "is_active\n",
      "name\n"
     ]
    }
   ],
   "source": [
    "OS.print_summary(\"example/example_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39990dc7",
   "metadata": {},
   "source": [
    "Before being stored in the `h5` archive the bytecode is wrapped in `np.void` which has a size limit. To get around this the bytecode is chunked and the chunks are wrapped in `np.void`. By default the chunks are hidden in the printed summary; they can be viewed using the `chunks` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a01817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      "config/config_data\n",
      "config/config_data/chunk_0\n",
      "config/parent_config_data\n",
      "config/parent_config_data/chunk_0\n",
      "data\n",
      "data/chunk_0\n",
      "id\n",
      "id/chunk_0\n",
      "is_active\n",
      "is_active/chunk_0\n",
      "name\n",
      "name/chunk_0\n"
     ]
    }
   ],
   "source": [
    "OS.print_summary(\"example/example_data.h5\", chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c92f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
